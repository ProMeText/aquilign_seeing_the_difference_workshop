{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e710e2-b398-47ba-a89c-6124cfb65b76",
   "metadata": {},
   "source": [
    "# Étape 1. Entraînement d'un segmenteur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9681c4bb-d184-4c82-aeeb-3f1874372305",
   "metadata": {},
   "source": [
    "Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb4b821-dad7-4a45-91de-8346ae4d6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import sys\n",
    "from transformers import BertTokenizer, Trainer, TrainingArguments, AutoModelForTokenClassification, set_seed\n",
    "sys.path.insert(1, '../aquilign')\n",
    "import preproc.tok_trainer_functions as trainer_functions\n",
    "import preproc.eval as evaluation\n",
    "import preproc.utils as utils\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import argparse\n",
    "#shutil usefull for deleting not empty directories \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8537553f-ad79-4d32-85d0-fab2d57b1836",
   "metadata": {},
   "source": [
    "L'exécution du script permet d'entraîner un modèle de segmentation automatique de texte. Trois fichiers doivent être fournis, tous au format spécifié (chaque token devant être identifié comme segmentant le texte doit être précédé d'un '£') : un fichier contenant les données d'entraînement, un contenant les données de dev, et un dernier contenant les données de test. Les fichiers doivent être dans un dossier contenant le code ISO de la langue dans laquelle ils sont écrits (ce code est récupéré au moment de l'évaluation des modèles).\n",
    "\n",
    "Le meilleur modèle est enregistré à la fin de l'entraînement. L'évaluation se base à la fois sur la loss, et sur les métriques plus classiques d'évaluation. Dans notre script, c'est la précision qui prend le poids le plus important.\n",
    "L'évaluation passe également par l'évaluation comparée d'une segmentation basée sur des regex. Il est donc nécessaire de remplir le fichier delimiters.json avec des exemple de regex.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77799585-3a43-4343-bdab-24f61cc08628",
   "metadata": {},
   "outputs": [],
   "source": [
    "## command line usage : python tok_trainer.py model_name tok_name train_file.txt dev_file.txt num_train_epochs batch_size logging_steps\n",
    "## where :\n",
    "# model_name is the full name of the model (same name for model and tokenizer or not)\n",
    "# tok_name is the full name of the tokenizer (can be the same)\n",
    "# train_file.txt is the file with the sentences and words of interest are identified  (words are identified with £ in the line)\n",
    "# which will be used for training\n",
    "## ex. : uoulentiers £mais il nen est pas encor temps. £Certes fait elle\n",
    "# dev_file.txt is the file with the sentences and words of interest which will be used for eval\n",
    "# num_train_epochs : the number of epochs we want to train (ex : 10)\n",
    "# batch_size : the batch size (ex : 8)\n",
    "# logging_steps : the number of logging steps (ex : 50)\n",
    "\n",
    "## was changed : if you want to fine-tune a model, we need to have two different names for model_name and tok_name (can also be the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b455a345-a250-4340-baee-d5a9cd9b49b0",
   "metadata": {},
   "source": [
    "La fonction training_trainer prend plusieurs arguments :\n",
    "- model_name : le nom du modèle AutoModelForTokenClassification\n",
    "- tok_name : le nom du modèle BertTokenizer\n",
    "(ces deux noms peuvent éventuellement être les mêmes, si l'on ne fine-tune pas un modèle spécifique)\n",
    "- train_dataset : le chemin du fichier des données d'entraînement\n",
    "- dev_dataset : le chemin du fichier des données de dev\n",
    "- eval_dataset : le chemin du fichier des données de test\n",
    "- num_train_epochs : le nombre d'époques d'entraînement (min. 2)\n",
    "- batch_size\n",
    "- logging_steps\n",
    "  \n",
    "Et en plus, un argument permettant de dire si on veut aussi garder la ponctuation ou non comme aide à la segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ba8ae12-6c46-49be-a526-c53b6d0ede10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_trainer(model_name, tok_name, train_dataset, dev_dataset, eval_dataset, num_train_epochs, batch_size, logging_steps, keep_punct=True):\n",
    "    model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=3)\n",
    "    tokenizer = BertTokenizer.from_pretrained(tok_name, max_length=10)\n",
    "    \n",
    "    with open(train_dataset, \"r\") as train_file:\n",
    "        train_lines = [item.replace(\"\\n\", \"\") for item in train_file.readlines()]\n",
    "        if keep_punct is False:\n",
    "            train_lines = [utils.remove_punctuation(line) for line in train_lines]\n",
    "        \n",
    "    with open(dev_dataset, \"r\") as dev_file:\n",
    "        dev_lines = [item.replace(\"\\n\", \"\") for item in dev_file.readlines()]\n",
    "        if keep_punct is False:\n",
    "            dev_lines = [utils.remove_punctuation(line) for line in dev_lines]\n",
    "        \n",
    "    with open(eval_dataset, \"r\") as eval_files:\n",
    "        eval_lines = [item.replace(\"\\n\", \"\") for item in eval_files.readlines()]\n",
    "    eval_data_lang = eval_dataset.split(\"/\")[-2]\n",
    "    \n",
    "    # Train corpus\n",
    "    train_texts_and_labels = utils.convertToSubWordsSentencesAndLabels(train_lines, tokenizer=tokenizer, delimiter=\"£\")\n",
    "    train_dataset = trainer_functions.SentenceBoundaryDataset(train_texts_and_labels, tokenizer)\n",
    "    \n",
    "    # Dev corpus\n",
    "    dev_texts_and_labels = utils.convertToSubWordsSentencesAndLabels(dev_lines, tokenizer=tokenizer, delimiter=\"£\")\n",
    "    dev_dataset = trainer_functions.SentenceBoundaryDataset(dev_texts_and_labels, tokenizer)\n",
    "\n",
    "    if '/' in model_name:\n",
    "        name_of_model = re.split('/', model_name)[1]\n",
    "    else:\n",
    "        name_of_model = model_name\n",
    "\n",
    "    # training arguments\n",
    "    # num train epochs, logging_steps and batch_size should be provided\n",
    "    # evaluation is done by epoch and the best model of each one is stored in a folder \"results_+name\"\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"results_{name_of_model}/epoch{num_train_epochs}_bs{batch_size}\",\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        logging_steps=logging_steps,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        dataloader_num_workers=8,\n",
    "        dataloader_prefetch_factor=4,\n",
    "        # ajout pour résoudre pb : save_safetensors= False et bf16=False\n",
    "        bf16=False,    \n",
    "        save_safetensors=False,\n",
    "        #modif : cpu\n",
    "        use_cpu=True,\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True\n",
    "        # best model is evaluated on loss\n",
    "    )\n",
    "\n",
    "    # define the trainer : model, training args, datasets and the specific compute_metrics defined in functions file\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "        compute_metrics=trainer_functions.compute_metrics\n",
    "    )\n",
    "\n",
    "    # fine-tune the model\n",
    "    print(\"Starting training\")\n",
    "    trainer.train()\n",
    "    print(\"End of training\")\n",
    "\n",
    "    # get the best model path\n",
    "    best_model_path = trainer.state.best_model_checkpoint\n",
    "    print(best_model_path)\n",
    "    print(f\"Evaluation.\")\n",
    "    \n",
    "    \n",
    "    # print the whole log_history with the compute metrics\n",
    "    best_precision_step, best_step_metrics = utils.get_best_step(trainer.state.log_history)\n",
    "    best_model_path = f\"results_{name_of_model}/epoch{num_train_epochs}_bs{batch_size}/checkpoint-{best_precision_step}\"\n",
    "    print(f\"Best model path according to precision: {best_model_path}\")\n",
    "    print(f\"Full metrics: {best_step_metrics}\")\n",
    "    \n",
    "    eval_results = evaluation.run_eval(data=eval_lines, \n",
    "                        model_path=best_model_path, \n",
    "                        tokenizer_name=tokenizer.name_or_path, \n",
    "                        verbose=False, \n",
    "                        lang=eval_data_lang)\n",
    "    \n",
    "\n",
    "    # We move the best state dir name to \"best\"\n",
    "    new_best_path = f\"results_{name_of_model}/epoch{num_train_epochs}_bs{batch_size}/best\"\n",
    "    try:\n",
    "        #os.rmdir(new_best_path)\n",
    "        shutil.rmtree(new_best_path)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    os.rename(best_model_path, new_best_path)\n",
    "    \n",
    "    #with open(f\"{new_best_path}/model_name\", \"w\") as model_name:\n",
    "    #    model_name.write(modelName)\n",
    "\n",
    "    with open(f\"{new_best_path}/eval.txt\", \"w\") as evaluation_results:\n",
    "        evaluation_results.write(eval_results)\n",
    "\n",
    "    with open(f\"{new_best_path}/metrics.json\", \"w\") as metrics:\n",
    "        json.dump(best_step_metrics, metrics)\n",
    "    \n",
    "    print(f\"\\n\\nBest model can be found at : {new_best_path} \")\n",
    "    print(f\"You should remove the following directories by using `rm -r results_{name_of_model}/epoch{num_train_epochs}_bs{batch_size}/checkpoint-*`\")\n",
    "\n",
    "    # functions returns best model_path\n",
    "    return new_best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5d9d75-163a-4e61-a1bf-ef8a32417db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-french-europeana-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Accelerator.__init__() got an unexpected keyword argument 'dispatch_batches'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdbmdz/bert-base-french-europeana-cased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdbmdz/bert-base-french-europeana-cased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/data_to_segmenter/fr/randomSentencesComplete-gf.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/data_to_segmenter/fr/randomSentencesEvalComplete-gf.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/data_to_segmenter/fr/randomSentencesfrancais-pourtest-complete-gf.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_punct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 56\u001b[0m, in \u001b[0;36mtraining_trainer\u001b[0;34m(model_name, tok_name, train_dataset, dev_dataset, eval_dataset, num_train_epochs, batch_size, logging_steps, keep_punct)\u001b[0m\n\u001b[1;32m     35\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     36\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_of_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_train_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_bs\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     37\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39mnum_train_epochs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# best model is evaluated on loss\u001b[39;00m\n\u001b[1;32m     53\u001b[0m )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# define the trainer : model, training args, datasets and the specific compute_metrics defined in functions file\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# fine-tune the model\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Bureau/Travail/projets/alignement/alignement_multilingue/bertalign/3.10_env/lib/python3.10/site-packages/transformers/trainer.py:367\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_in_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_accelerator_and_postprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker \u001b[38;5;241m=\u001b[39m TrainerMemoryTracker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mskip_memory_metrics)\n",
      "File \u001b[0;32m~/Bureau/Travail/projets/alignement/alignement_multilingue/bertalign/3.10_env/lib/python3.10/site-packages/transformers/trainer.py:4127\u001b[0m, in \u001b[0;36mTrainer.create_accelerator_and_postprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4122\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(accelerator_kwargs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m   4123\u001b[0m         \u001b[38;5;66;03m# Some values may need to go through non-accelerate aligned defaults\u001b[39;00m\n\u001b[1;32m   4124\u001b[0m         \u001b[38;5;66;03m# and we need to run the `__post_init__` to set them\u001b[39;00m\n\u001b[1;32m   4125\u001b[0m         accelerator_kwargs \u001b[38;5;241m=\u001b[39m AcceleratorConfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maccelerator_kwargs)\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m-> 4127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;241m=\u001b[39m \u001b[43mAccelerator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeepspeed_plugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepspeed_plugin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_plugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_accumulation_plugin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4130\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maccelerator_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4132\u001b[0m \u001b[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001b[39;00m\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather_for_metrics\n",
      "\u001b[0;31mTypeError\u001b[0m: Accelerator.__init__() got an unexpected keyword argument 'dispatch_batches'"
     ]
    }
   ],
   "source": [
    "training_trainer('dbmdz/bert-base-french-europeana-cased', 'dbmdz/bert-base-french-europeana-cased', '../data/data_to_segmenter/fr/randomSentencesComplete-gf.txt', '../data/data_to_segmenter/fr/randomSentencesEvalComplete-gf.txt', '../data/data_to_segmenter/fr/randomSentencesfrancais-pourtest-complete-gf.txt', 2, 8, 50, keep_punct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4398892-3143-4904-b9cc-1743ff6647e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21993a7-b776-4d3b-9076-bbafa54870e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f737321-8f03-49e0-9d71-1c572942ccbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9c48b-07a0-4ef6-ba1f-ea4cbbf34bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4b0a1-1e80-4a9d-8dbb-bc2f60c41b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10_env",
   "language": "python",
   "name": "3.10_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
